{"cells":[{"cell_type":"code","execution_count":95,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-18T14:32:55.788149Z","iopub.status.busy":"2023-11-18T14:32:55.787732Z","iopub.status.idle":"2023-11-18T14:32:55.803462Z","shell.execute_reply":"2023-11-18T14:32:55.802532Z","shell.execute_reply.started":"2023-11-18T14:32:55.788112Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/emotions-dataset-for-nlp/val.txt\n","/kaggle/input/emotions-dataset-for-nlp/test.txt\n","/kaggle/input/emotions-dataset-for-nlp/train.txt\n","/kaggle/input/bangla-translated-5k/val_translated - Sheet1.csv\n","/kaggle/input/bangla-translated-5k/translated-5k - Sheet1.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:32:55.806076Z","iopub.status.busy":"2023-11-18T14:32:55.805680Z","iopub.status.idle":"2023-11-18T14:32:55.812438Z","shell.execute_reply":"2023-11-18T14:32:55.811359Z","shell.execute_reply.started":"2023-11-18T14:32:55.806037Z"},"trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm, trange\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertPreTrainedModel, BertModel\n","\n","from transformers import AutoConfig, AutoTokenizer"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:32:55.814139Z","iopub.status.busy":"2023-11-18T14:32:55.813670Z","iopub.status.idle":"2023-11-18T14:33:10.343806Z","shell.execute_reply":"2023-11-18T14:33:10.342913Z","shell.execute_reply.started":"2023-11-18T14:32:55.814109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/csebuetnlp/normalizer\n","  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-6h731nfx\n","Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from normalizer==0.0.1) (2020.4.4)\n","Collecting emoji==1.4.2\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[K     |████████████████████████████████| 184 kB 7.3 MB/s eta 0:00:01\n","\u001b[?25hCollecting ftfy==6.0.3\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s  eta 0:00:01\n","\u001b[?25hRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.1.9)\n","Building wheels for collected packages: normalizer, emoji, ftfy\n","  Building wheel for normalizer (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for normalizer: filename=normalizer-0.0.1-py3-none-any.whl size=6885 sha256=521fbc9d89f1a671317b9ffe736c9e95fbe7e732801ad7d1ad277b951ebf4383\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i4tcgb1u/wheels/af/b1/ee/b9e2a2f2dd861976a357b6a6fa105aeedf2254016676f6cf8f\n","  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186451 sha256=05ed65a000e83e6bf217adaef8e65f23c8ac1b8a9cac34b0f8071bed3f0e122a\n","  Stored in directory: /root/.cache/pip/wheels/e4/61/e7/2fc1ac8f306848fc66c6c013ab511f0a39ef4b1825b11363b2\n","  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41913 sha256=eb4bfc4629b5ecd50bb72829115d8fcc79fb9607564a6f1e4e5427ba24fb163f\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","Successfully built normalizer emoji ftfy\n","Installing collected packages: ftfy, emoji, normalizer\n","  Attempting uninstall: emoji\n","    Found existing installation: emoji 0.6.0\n","    Uninstalling emoji-0.6.0:\n","      Successfully uninstalled emoji-0.6.0\n","Successfully installed emoji-1.4.2 ftfy-6.0.3 normalizer-0.0.1\n","\u001b[33mWARNING: You are using pip version 20.3.1; however, version 23.3.1 is available.\n","You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["# !pip install transformers\n","from transformers import AutoModelForPreTraining, AutoTokenizer\n","from transformers import BertTokenizer, TFBertModel\n","!pip install git+https://github.com/csebuetnlp/normalizer\n","from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n","import torch"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.345795Z","iopub.status.busy":"2023-11-18T14:33:10.345483Z","iopub.status.idle":"2023-11-18T14:33:10.350024Z","shell.execute_reply":"2023-11-18T14:33:10.348943Z","shell.execute_reply.started":"2023-11-18T14:33:10.345761Z"},"trusted":true},"outputs":[],"source":["from sklearn import metrics\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"markdown","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"source":["## Load data"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.353104Z","iopub.status.busy":"2023-11-18T14:33:10.352809Z","iopub.status.idle":"2023-11-18T14:33:10.387497Z","shell.execute_reply":"2023-11-18T14:33:10.386923Z","shell.execute_reply.started":"2023-11-18T14:33:10.353076Z"},"trusted":true},"outputs":[],"source":["translated_df = pd.read_csv('/kaggle/input/bangla-translated-5k/translated-5k - Sheet1.csv',sep=',').sample(frac=1) #shuffling the data for train-val split\n","# test_df = pd.read_csv('../input/emotions-dataset-for-nlp/test.txt', sep=';')\n","# val_df = pd.read_csv('/kaggle/input/bangla-translated-5k/val (1).csv',sep=',').sample(frac=1)"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.390214Z","iopub.status.busy":"2023-11-18T14:33:10.389938Z","iopub.status.idle":"2023-11-18T14:33:10.402171Z","shell.execute_reply":"2023-11-18T14:33:10.401442Z","shell.execute_reply.started":"2023-11-18T14:33:10.390186Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>emotion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>617</th>\n","      <td>আমি ইদানীং একটু অলস বোধ করছি কিন্তু স্কুল এখনও...</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>193</th>\n","      <td>আমি চাই যে লোকেরা আস্থা রাখুক যে তারা আমার চেয...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>3884</th>\n","      <td>আমি হারিয়েছি এবং তারপরে নভেম্বরে খুঁজে পেয়েছ...</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>3374</th>\n","      <td>সারা বছর ধরে আপনাদের কারো সাথে না থাকার কারণে ...</td>\n","      <td>anger</td>\n","    </tr>\n","    <tr>\n","      <th>1332</th>\n","      <td>আরও কিছু করার জন্য আমাকে ক্রমাগত নিজের মধ্যে গ...</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>4912</th>\n","      <td>আমি বিশ্বের দ্বারা অন্যায় বোধ করি</td>\n","      <td>anger</td>\n","    </tr>\n","    <tr>\n","      <th>1045</th>\n","      <td>এমনকি একটি জীবন-হুমকিপূর্ণ রোগে আক্রান্ত হওয়া...</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>1857</th>\n","      <td>আমি সবেমাত্র অত্যন্ত বিতাড়িত এবং নিরাপত্তাহীন...</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>4669</th>\n","      <td>আমার মনে হচ্ছে আমি এটাকে কুইল্ট করার গতি সহ্য ...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>2721</th>\n","      <td>আমি পরের বছরটিকে একটি দুঃসাহসিক কাজ হিসাবে দেখ...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>4954</th>\n","      <td>আমি এই প্রভাবশালী কন্ঠের জিনটি প্রকাশ করি এটা ...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>238</th>\n","      <td>আমি দৃঢ়ভাবে অনুভব করি যে যারা আঙুল নির্দেশ কর...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>1755</th>\n","      <td>আমি অনুভব করি যে সে আন্তরিক ছিল যখন সে বলে যে ...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>3134</th>\n","      <td>আমি মনে করি না যে আমরা এখনও সেই বিন্দুতে পৌঁছে...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>4122</th>\n","      <td>আমি মনে করি তারা আমার ব্লগে বেশ নিরাপদ</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>1127</th>\n","      <td>আমি একটু চাপ অনুভব করছি এই ভেবে যে ট্রিপটি বাস...</td>\n","      <td>anger</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>তার জন্য আমার অনেক ভালবাসা এবং উষ্ণতার অনুভূতি...</td>\n","      <td>anger</td>\n","    </tr>\n","    <tr>\n","      <th>2776</th>\n","      <td>আমি ভাগ্যকে অনুরোধ করছি পরের চক্রের সাথে তালগো...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>549</th>\n","      <td>আমি একরকম বিরক্ত বোধ করছি যে স্কুল বছর অর্ধেক ...</td>\n","      <td>anger</td>\n","    </tr>\n","    <tr>\n","      <th>3303</th>\n","      <td>আমি আমার মডিউলগুলির সাথে কীভাবে পারফর্ম করছি ত...</td>\n","      <td>fear</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sentence  emotion\n","617   আমি ইদানীং একটু অলস বোধ করছি কিন্তু স্কুল এখনও...  sadness\n","193   আমি চাই যে লোকেরা আস্থা রাখুক যে তারা আমার চেয...      joy\n","3884  আমি হারিয়েছি এবং তারপরে নভেম্বরে খুঁজে পেয়েছ...  sadness\n","3374  সারা বছর ধরে আপনাদের কারো সাথে না থাকার কারণে ...    anger\n","1332  আরও কিছু করার জন্য আমাকে ক্রমাগত নিজের মধ্যে গ...  sadness\n","4912                 আমি বিশ্বের দ্বারা অন্যায় বোধ করি    anger\n","1045  এমনকি একটি জীবন-হুমকিপূর্ণ রোগে আক্রান্ত হওয়া...  sadness\n","1857  আমি সবেমাত্র অত্যন্ত বিতাড়িত এবং নিরাপত্তাহীন...     fear\n","4669  আমার মনে হচ্ছে আমি এটাকে কুইল্ট করার গতি সহ্য ...      joy\n","2721  আমি পরের বছরটিকে একটি দুঃসাহসিক কাজ হিসাবে দেখ...      joy\n","4954  আমি এই প্রভাবশালী কন্ঠের জিনটি প্রকাশ করি এটা ...      joy\n","238   আমি দৃঢ়ভাবে অনুভব করি যে যারা আঙুল নির্দেশ কর...      joy\n","1755  আমি অনুভব করি যে সে আন্তরিক ছিল যখন সে বলে যে ...      joy\n","3134  আমি মনে করি না যে আমরা এখনও সেই বিন্দুতে পৌঁছে...      joy\n","4122             আমি মনে করি তারা আমার ব্লগে বেশ নিরাপদ      joy\n","1127  আমি একটু চাপ অনুভব করছি এই ভেবে যে ট্রিপটি বাস...    anger\n","131   তার জন্য আমার অনেক ভালবাসা এবং উষ্ণতার অনুভূতি...    anger\n","2776  আমি ভাগ্যকে অনুরোধ করছি পরের চক্রের সাথে তালগো...      joy\n","549   আমি একরকম বিরক্ত বোধ করছি যে স্কুল বছর অর্ধেক ...    anger\n","3303  আমি আমার মডিউলগুলির সাথে কীভাবে পারফর্ম করছি ত...     fear"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["translated_df.head(20)"]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.403873Z","iopub.status.busy":"2023-11-18T14:33:10.403559Z","iopub.status.idle":"2023-11-18T14:33:10.412732Z","shell.execute_reply":"2023-11-18T14:33:10.411883Z","shell.execute_reply.started":"2023-11-18T14:33:10.403825Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","new_df = pd.DataFrame(translated_df)\n","\n","train_df, val_df = train_test_split(\n","    new_df,\n","    test_size=0.20,\n","    random_state=24000,\n","    shuffle=True,\n",")"]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.414349Z","iopub.status.busy":"2023-11-18T14:33:10.414058Z","iopub.status.idle":"2023-11-18T14:33:10.424018Z","shell.execute_reply":"2023-11-18T14:33:10.422985Z","shell.execute_reply.started":"2023-11-18T14:33:10.414321Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((3999, 2), (1000, 2))"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape, val_df.shape"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.425719Z","iopub.status.busy":"2023-11-18T14:33:10.425303Z","iopub.status.idle":"2023-11-18T14:33:10.432339Z","shell.execute_reply":"2023-11-18T14:33:10.431370Z","shell.execute_reply.started":"2023-11-18T14:33:10.425679Z"},"trusted":true},"outputs":[],"source":["train_df.columns = ['sentence', 'emotion']\n","val_df.columns = ['sentence', 'emotion']"]},{"cell_type":"code","execution_count":104,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.434031Z","iopub.status.busy":"2023-11-18T14:33:10.433656Z","iopub.status.idle":"2023-11-18T14:33:10.475309Z","shell.execute_reply":"2023-11-18T14:33:10.474568Z","shell.execute_reply.started":"2023-11-18T14:33:10.434003Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                               sentence  emotion\n","2113  আমি অনুভব করি আমাদের পৃথিবী তখন অনেক বেশি নিষ্...      joy\n","3942  আমি ঘরে ঢুকে মোটামুটি শান্ত বোধ করলাম ফটোগ্রাফ...      joy\n","2511               আমি আমার মিষ্টি ছেলের জন্য অনুভব করি     love\n","619   আমি ঠিক সেই দিনের ইন্টারভিউ পোস্টের অংশে চলে য...      joy\n","4798  আমি এমনকি বলতে সাহস করি যে কিছু বড় স্টিলার এব...    anger\n","...                                                 ...      ...\n","1878  আমি এখন সেই ব্যথা অনুভব করছি এবং ভয় পাচ্ছি যে...     fear\n","2407  আমি মনে করি আমি সংগ্রাম করতে যাচ্ছি এবং ব্যর্থ...  sadness\n","4549  আমি আপনাকে অনেক দিন আগে পরীক্ষা করে দেখেছি আমি...      joy\n","4218  ক্লাসের প্রতিটি শিশুকে তারা মূল্যবান বলে মনে ক...      joy\n","2127  আমি কয়েক সপ্তাহ ধরে বিরক্তিকর ছিলাম এবং বৃষ্ট...  sadness\n","\n","[3999 rows x 2 columns]\n"]}],"source":["dataset = pd.DataFrame(data=train_df, columns=['sentence', 'emotion'])\n","dataset.to_csv(\"train.csv\")\n","print (dataset)"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.476648Z","iopub.status.busy":"2023-11-18T14:33:10.476377Z","iopub.status.idle":"2023-11-18T14:33:10.495167Z","shell.execute_reply":"2023-11-18T14:33:10.494344Z","shell.execute_reply.started":"2023-11-18T14:33:10.476621Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                               sentence   emotion\n","155   আমি সত্যিই ভুলে গিয়েছিলাম যে আন্তরিকভাবে হাসত...  surprise\n","1717  আমি বাইক চালিয়ে আমার আশেপাশে ফিরে আসি এবং আমা...       joy\n","371                      আমি ভেবেছিলাম আমি খালি বোধ করব   sadness\n","1037  আমি মূল্যহীন বোধ করি এবং আমি যে মূল্যবান সময় ...   sadness\n","2181          এই পরিবারকে জেনে আমি নিজেকে ধন্য মনে করছি      love\n","...                                                 ...       ...\n","4281  আমি তাকে সমর্থন বোধ করি আমি সাহায্য করতে পারি ...      love\n","4110  আমি কুৎসিত বোধ করি আমি একটি সুন্দর পোষাকের চেয...   sadness\n","4861  আমি একটি কিশোরী মেয়ের কথা শুনেছিলাম যে তার মু...   sadness\n","4606  আমি একটু কল্পনা করতে ঘৃণা করব যদি সেক্রেটারি স...     anger\n","2662  আমি বরং হৃদয়হীন বোধ করছি কারণ আমি সম্প্রতি নি...     anger\n","\n","[1000 rows x 2 columns]\n"]}],"source":["dataset = pd.DataFrame(data=val_df, columns=['sentence', 'emotion'])\n","dataset.to_csv(\"val.csv\")\n","print (dataset)"]},{"cell_type":"code","execution_count":106,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.496744Z","iopub.status.busy":"2023-11-18T14:33:10.496372Z","iopub.status.idle":"2023-11-18T14:33:10.506098Z","shell.execute_reply":"2023-11-18T14:33:10.505265Z","shell.execute_reply.started":"2023-11-18T14:33:10.496705Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>emotion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2113</th>\n","      <td>আমি অনুভব করি আমাদের পৃথিবী তখন অনেক বেশি নিষ্...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>3942</th>\n","      <td>আমি ঘরে ঢুকে মোটামুটি শান্ত বোধ করলাম ফটোগ্রাফ...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>2511</th>\n","      <td>আমি আমার মিষ্টি ছেলের জন্য অনুভব করি</td>\n","      <td>love</td>\n","    </tr>\n","    <tr>\n","      <th>619</th>\n","      <td>আমি ঠিক সেই দিনের ইন্টারভিউ পোস্টের অংশে চলে য...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>4798</th>\n","      <td>আমি এমনকি বলতে সাহস করি যে কিছু বড় স্টিলার এব...</td>\n","      <td>anger</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sentence emotion\n","2113  আমি অনুভব করি আমাদের পৃথিবী তখন অনেক বেশি নিষ্...     joy\n","3942  আমি ঘরে ঢুকে মোটামুটি শান্ত বোধ করলাম ফটোগ্রাফ...     joy\n","2511               আমি আমার মিষ্টি ছেলের জন্য অনুভব করি    love\n","619   আমি ঠিক সেই দিনের ইন্টারভিউ পোস্টের অংশে চলে য...     joy\n","4798  আমি এমনকি বলতে সাহস করি যে কিছু বড় স্টিলার এব...   anger"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":107,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.507722Z","iopub.status.busy":"2023-11-18T14:33:10.507361Z","iopub.status.idle":"2023-11-18T14:33:10.518865Z","shell.execute_reply":"2023-11-18T14:33:10.518100Z","shell.execute_reply.started":"2023-11-18T14:33:10.507678Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>emotion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>155</th>\n","      <td>আমি সত্যিই ভুলে গিয়েছিলাম যে আন্তরিকভাবে হাসত...</td>\n","      <td>surprise</td>\n","    </tr>\n","    <tr>\n","      <th>1717</th>\n","      <td>আমি বাইক চালিয়ে আমার আশেপাশে ফিরে আসি এবং আমা...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>371</th>\n","      <td>আমি ভেবেছিলাম আমি খালি বোধ করব</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>1037</th>\n","      <td>আমি মূল্যহীন বোধ করি এবং আমি যে মূল্যবান সময় ...</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>2181</th>\n","      <td>এই পরিবারকে জেনে আমি নিজেকে ধন্য মনে করছি</td>\n","      <td>love</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sentence   emotion\n","155   আমি সত্যিই ভুলে গিয়েছিলাম যে আন্তরিকভাবে হাসত...  surprise\n","1717  আমি বাইক চালিয়ে আমার আশেপাশে ফিরে আসি এবং আমা...       joy\n","371                      আমি ভেবেছিলাম আমি খালি বোধ করব   sadness\n","1037  আমি মূল্যহীন বোধ করি এবং আমি যে মূল্যবান সময় ...   sadness\n","2181          এই পরিবারকে জেনে আমি নিজেকে ধন্য মনে করছি      love"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["val_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## EDA"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.520421Z","iopub.status.busy":"2023-11-18T14:33:10.520105Z","iopub.status.idle":"2023-11-18T14:33:10.531359Z","shell.execute_reply":"2023-11-18T14:33:10.530434Z","shell.execute_reply.started":"2023-11-18T14:33:10.520393Z"},"trusted":true},"outputs":[{"data":{"text/plain":["joy         1383\n","sadness     1114\n","anger        553\n","fear         439\n","love         358\n","surprise     152\n","Name: emotion, dtype: int64"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["train_df['emotion'].value_counts()"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.532785Z","iopub.status.busy":"2023-11-18T14:33:10.532505Z","iopub.status.idle":"2023-11-18T14:33:10.545149Z","shell.execute_reply":"2023-11-18T14:33:10.544403Z","shell.execute_reply.started":"2023-11-18T14:33:10.532753Z"},"trusted":true},"outputs":[{"data":{"text/plain":["joy         365\n","sadness     269\n","anger       147\n","fear        107\n","love         74\n","surprise     38\n","Name: emotion, dtype: int64"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["val_df['emotion'].value_counts()"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.546483Z","iopub.status.busy":"2023-11-18T14:33:10.546225Z","iopub.status.idle":"2023-11-18T14:33:10.709717Z","shell.execute_reply":"2023-11-18T14:33:10.708732Z","shell.execute_reply.started":"2023-11-18T14:33:10.546457Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","# from matplotlib_inline import backend_inline\n","# backend_inline.set_matplotlib_formats('svg') # HD Plots\n","\n","translated_df['emotion'].value_counts(ascending=True).plot.barh()\n","plt.title('Class Distribution')\n","plt.show()"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.711467Z","iopub.status.busy":"2023-11-18T14:33:10.711149Z","iopub.status.idle":"2023-11-18T14:33:10.731780Z","shell.execute_reply":"2023-11-18T14:33:10.730911Z","shell.execute_reply.started":"2023-11-18T14:33:10.711434Z"},"trusted":true},"outputs":[{"data":{"text/plain":["67"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["# get max len of sentences\n","def max_len(data):\n","    return data['sentence'].apply(lambda x: len(x.split())).max()\n","\n","max_lens = [max_len(train_df), max_len(val_df)]\n","max(max_lens)"]},{"cell_type":"code","execution_count":112,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.733465Z","iopub.status.busy":"2023-11-18T14:33:10.733183Z","iopub.status.idle":"2023-11-18T14:33:10.741080Z","shell.execute_reply":"2023-11-18T14:33:10.740184Z","shell.execute_reply.started":"2023-11-18T14:33:10.733439Z"},"trusted":true},"outputs":[],"source":["# len(train_df['sentence'].iloc[4].split())"]},{"cell_type":"code","execution_count":113,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.742659Z","iopub.status.busy":"2023-11-18T14:33:10.742397Z","iopub.status.idle":"2023-11-18T14:33:10.751869Z","shell.execute_reply":"2023-11-18T14:33:10.751031Z","shell.execute_reply.started":"2023-11-18T14:33:10.742634Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[67, 60]"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["max_lens"]},{"cell_type":"markdown","metadata":{},"source":["## Configs"]},{"cell_type":"code","execution_count":114,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.753062Z","iopub.status.busy":"2023-11-18T14:33:10.752765Z","iopub.status.idle":"2023-11-18T14:33:10.761501Z","shell.execute_reply":"2023-11-18T14:33:10.760579Z","shell.execute_reply.started":"2023-11-18T14:33:10.753034Z"},"trusted":true},"outputs":[],"source":["\n","MODEL_OUT_DIR = '/kaggle/working/models/bert_emotion'\n","TRAIN_FILE_PATH = '/kaggle/input/bangla-translated-5k/translated-5k - Sheet1.csv'\n","VALID_FILE_PATH = '/kaggle/input/bangla-translated-5k/val_translated - Sheet1.csv'\n","# TEST_FILE_PATH = '../input/emotions-dataset-for-nlp/test.txt'\n","## Model Configurations\n","MAX_LEN_TRAIN = 67\n","MAX_LEN_VALID = 55\n","# MAX_LEN_TEST = 68\n","BATCH_SIZE = 8\n","LR = 1e-5\n","NUM_EPOCHS = 10\n","# NUM_THREADS = 1  ## Number of threads for collecting dataset\n","MODEL_NAME = 'csebuetnlp/banglabert' #bert-large-uncased bert-base-uncased\n","LABEL_DICT = {'joy':0, 'sadness':1, 'anger':2, 'fear':3, 'love':4, 'surprise':5}\n","\n","if not os.path.isdir(MODEL_OUT_DIR):\n","    os.makedirs(MODEL_OUT_DIR)"]},{"cell_type":"markdown","metadata":{},"source":["## Create Dataset"]},{"cell_type":"code","execution_count":115,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.762917Z","iopub.status.busy":"2023-11-18T14:33:10.762632Z","iopub.status.idle":"2023-11-18T14:33:10.776188Z","shell.execute_reply":"2023-11-18T14:33:10.775231Z","shell.execute_reply.started":"2023-11-18T14:33:10.762889Z"},"trusted":true},"outputs":[],"source":["class Emotions_Dataset(Dataset):\n","\n","    def __init__(self, filename, maxlen, tokenizer, label_dict): \n","        #Store the contents of the file in a pandas dataframe\n","        self.df = pd.read_csv(filename, delimiter = ',')\n","        # name columns\n","        self.df.columns = ['sentence', 'emotion']\n","        #Initialize the tokenizer for the desired transformer model\n","        self.df['emotion'] = self.df['emotion'].map(label_dict)\n","        self.tokenizer = tokenizer\n","        #Maximum length of the tokens list to keep all the sequences of fixed size\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):    \n","        #Select the sentence and label at the specified index in the data frame\n","        sentence = self.df.loc[index, 'sentence']\n","        label = self.df.loc[index, 'emotion']\n","        #Preprocess the text to be suitable for the transformer\n","        tokens = self.tokenizer.tokenize(sentence) \n","        tokens = ['[CLS]'] + tokens + ['[SEP]'] \n","        if len(tokens) < self.maxlen:\n","            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] \n","        else:\n","            tokens = tokens[:self.maxlen-1] + ['[SEP]'] \n","        #Obtain the indices of the tokens in the BERT Vocabulary\n","        input_ids = self.tokenizer.convert_tokens_to_ids(tokens) \n","        input_ids = torch.tensor(input_ids) \n","        #Obtain the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n","        attention_mask = (input_ids != 0).long()\n","        \n","        label = torch.tensor(label, dtype=torch.long)\n","        \n","        return input_ids, attention_mask, label"]},{"cell_type":"code","execution_count":116,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.777798Z","iopub.status.busy":"2023-11-18T14:33:10.777464Z","iopub.status.idle":"2023-11-18T14:33:10.788929Z","shell.execute_reply":"2023-11-18T14:33:10.788207Z","shell.execute_reply.started":"2023-11-18T14:33:10.777769Z"},"trusted":true},"outputs":[],"source":["class BertEmotionClassifier(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.bert = BertModel(config)\n","        #The classification layer that takes the [CLS] representation and outputs the logit\n","        self.cls_layer = nn.Linear(config.hidden_size, 6)\n","\n","    def forward(self, input_ids, attention_mask):\n","        #Feed the input to Bert model to obtain contextualized representations\n","        reps, _ = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        #Obtain the representations of [CLS] heads\n","        cls_reps = reps[:, 0]\n","        logits = self.cls_layer(cls_reps)\n","        return logits"]},{"cell_type":"code","execution_count":117,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.790307Z","iopub.status.busy":"2023-11-18T14:33:10.790036Z","iopub.status.idle":"2023-11-18T14:33:10.802814Z","shell.execute_reply":"2023-11-18T14:33:10.802045Z","shell.execute_reply.started":"2023-11-18T14:33:10.790281Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(3999, 2)"]},"execution_count":117,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape"]},{"cell_type":"code","execution_count":118,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.804412Z","iopub.status.busy":"2023-11-18T14:33:10.804108Z","iopub.status.idle":"2023-11-18T14:33:10.813441Z","shell.execute_reply":"2023-11-18T14:33:10.812503Z","shell.execute_reply.started":"2023-11-18T14:33:10.804385Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(1000, 2)"]},"execution_count":118,"metadata":{},"output_type":"execute_result"}],"source":["val_df.shape"]},{"cell_type":"code","execution_count":119,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.814729Z","iopub.status.busy":"2023-11-18T14:33:10.814463Z","iopub.status.idle":"2023-11-18T14:33:10.827827Z","shell.execute_reply":"2023-11-18T14:33:10.827084Z","shell.execute_reply.started":"2023-11-18T14:33:10.814703Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>emotion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>155</th>\n","      <td>আমি সত্যিই ভুলে গিয়েছিলাম যে আন্তরিকভাবে হাসত...</td>\n","      <td>surprise</td>\n","    </tr>\n","    <tr>\n","      <th>1717</th>\n","      <td>আমি বাইক চালিয়ে আমার আশেপাশে ফিরে আসি এবং আমা...</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>371</th>\n","      <td>আমি ভেবেছিলাম আমি খালি বোধ করব</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>1037</th>\n","      <td>আমি মূল্যহীন বোধ করি এবং আমি যে মূল্যবান সময় ...</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>2181</th>\n","      <td>এই পরিবারকে জেনে আমি নিজেকে ধন্য মনে করছি</td>\n","      <td>love</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sentence   emotion\n","155   আমি সত্যিই ভুলে গিয়েছিলাম যে আন্তরিকভাবে হাসত...  surprise\n","1717  আমি বাইক চালিয়ে আমার আশেপাশে ফিরে আসি এবং আমা...       joy\n","371                      আমি ভেবেছিলাম আমি খালি বোধ করব   sadness\n","1037  আমি মূল্যহীন বোধ করি এবং আমি যে মূল্যবান সময় ...   sadness\n","2181          এই পরিবারকে জেনে আমি নিজেকে ধন্য মনে করছি      love"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["val_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Training function"]},{"cell_type":"code","execution_count":120,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.829646Z","iopub.status.busy":"2023-11-18T14:33:10.829283Z","iopub.status.idle":"2023-11-18T14:33:10.840157Z","shell.execute_reply":"2023-11-18T14:33:10.839439Z","shell.execute_reply.started":"2023-11-18T14:33:10.829610Z"},"trusted":true},"outputs":[],"source":["def train(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n","    best_acc = 0\n","    for epoch in trange(epochs, desc=\"Epoch\"):\n","        model.train()\n","        train_acc = 0\n","        for i, (input_ids, attention_mask, labels) in enumerate(iterable=train_loader):\n","            optimizer.zero_grad()  \n","            \n","            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","            \n","            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n","            \n","            loss = criterion(logits, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            train_acc += get_accuracy_from_logits(logits, labels)\n","        \n","        print(f\"Training accuracy is {train_acc/len(train_loader)}\")\n","        val_acc, val_loss = evaluate(model=model, criterion=criterion, dataloader=val_loader, device=device)\n","        print(\"Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}\".format(epoch, val_acc, val_loss))\n","        \n","#         if val_acc > best_acc:\n","#             print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, val_acc))\n","#             best_acc = val_acc\n","#             model.save_pretrained(save_directory=MODEL_OUT_DIR + '/')\n","#             config.save_pretrained(save_directory=MODEL_OUT_DIR + '/')\n","#             tokenizer.save_pretrained(save_directory=MODEL_OUT_DIR + '/')"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation function"]},{"cell_type":"code","execution_count":121,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.841518Z","iopub.status.busy":"2023-11-18T14:33:10.841232Z","iopub.status.idle":"2023-11-18T14:33:10.854257Z","shell.execute_reply":"2023-11-18T14:33:10.853409Z","shell.execute_reply.started":"2023-11-18T14:33:10.841492Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, criterion, dataloader, device):\n","    model.eval()\n","    mean_acc, mean_loss, count = 0, 0, 0\n","#     predicted_labels = []\n","#     actual_labels = []\n","    with torch.no_grad():\n","        for input_ids, attention_mask, labels in (dataloader):\n","            \n","            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","            logits = model(input_ids, attention_mask)\n","            \n","            mean_loss += criterion(logits.squeeze(-1), labels).item()\n","            mean_acc += get_accuracy_from_logits(logits, labels)\n","            count += 1\n","            \n","#             predicted_labels += output\n","#             actual_labels += labels\n","            \n","    return mean_acc/count, mean_loss/count"]},{"cell_type":"code","execution_count":122,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.855904Z","iopub.status.busy":"2023-11-18T14:33:10.855516Z","iopub.status.idle":"2023-11-18T14:33:10.865999Z","shell.execute_reply":"2023-11-18T14:33:10.865340Z","shell.execute_reply.started":"2023-11-18T14:33:10.855868Z"},"trusted":true},"outputs":[],"source":["def get_accuracy_from_logits(logits, labels):\n","    probs = F.softmax(logits, dim=1)\n","    output = torch.argmax(probs, dim=1)\n","    acc = (output == labels).float().mean()\n","    return acc"]},{"cell_type":"markdown","metadata":{},"source":["## Predict function"]},{"cell_type":"code","execution_count":123,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.867429Z","iopub.status.busy":"2023-11-18T14:33:10.867137Z","iopub.status.idle":"2023-11-18T14:33:10.876773Z","shell.execute_reply":"2023-11-18T14:33:10.875928Z","shell.execute_reply.started":"2023-11-18T14:33:10.867402Z"},"trusted":true},"outputs":[],"source":["def predict(model, dataloader, device):\n","    predicted_label = []\n","    actual_label = []\n","    with torch.no_grad():\n","        for input_ids, attention_mask, labels in (dataloader):\n","            \n","            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","            logits = model(input_ids, attention_mask)\n","            \n","            probs = F.softmax(logits, dim=1)\n","            output = torch.argmax(probs, dim=1)\n","            \n","            predicted_label += output\n","            actual_label += labels\n","            \n","    return predicted_label, actual_label"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:10.878282Z","iopub.status.busy":"2023-11-18T14:33:10.878010Z","iopub.status.idle":"2023-11-18T14:33:27.036775Z","shell.execute_reply":"2023-11-18T14:33:27.035937Z","shell.execute_reply.started":"2023-11-18T14:33:10.878256Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9154e05fc8fd4a5abca9eba7ae7f17e3","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=586.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c0d5bfbe5db48aaa42b5924db4850db","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=528316.0, style=ProgressStyle(descripti…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a03c492a1afc4390913f3864e0161ae7","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f6beee441c84af6829b8eef8fa4bb1e","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=119.0, style=ProgressStyle(description_…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be15a637a4f24947829c35de7611e19e","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442560329.0, style=ProgressStyle(descri…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at csebuetnlp/banglabert were not used when initializing BertEmotionClassifier: ['electra.embeddings.position_ids', 'electra.embeddings.word_embeddings.weight', 'electra.embeddings.position_embeddings.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.embeddings.LayerNorm.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.output.LayerNorm.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing BertEmotionClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertEmotionClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertEmotionClassifier were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'cls_layer.bias', 'cls_layer.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","## Configuration loaded from AutoConfig \n","config = AutoConfig.from_pretrained(MODEL_NAME)\n","## Tokenizer loaded from AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","## Creating the model from the desired transformer model\n","model = BertEmotionClassifier.from_pretrained(MODEL_NAME, config=config)\n","## GPU or CPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","## Putting model to device\n","model = model.to(device)\n","## Takes as the input the logits of the positive class and computes the binary cross-entropy \n","# criterion = nn.BCEWithLogitsLoss()\n","criterion = nn.CrossEntropyLoss()\n","## Optimizer\n","optimizer = optim.Adam(params=model.parameters(), lr=LR)"]},{"cell_type":"code","execution_count":125,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:27.038636Z","iopub.status.busy":"2023-11-18T14:33:27.038366Z","iopub.status.idle":"2023-11-18T14:33:27.083463Z","shell.execute_reply":"2023-11-18T14:33:27.082730Z","shell.execute_reply.started":"2023-11-18T14:33:27.038611Z"},"trusted":true},"outputs":[],"source":["## Training Dataset\n","train_set = Emotions_Dataset(filename=TRAIN_FILE_PATH, maxlen=MAX_LEN_TRAIN, tokenizer=tokenizer, label_dict=LABEL_DICT)\n","valid_set = Emotions_Dataset(filename=VALID_FILE_PATH, maxlen=MAX_LEN_VALID, tokenizer=tokenizer, label_dict=LABEL_DICT)\n","# test_set = Emotions_Dataset(filename=TEST_FILE_PATH, maxlen=MAX_LEN_TEST, tokenizer=tokenizer, label_dict=LABEL_DICT)\n","\n","\n","## Data Loaders\n","train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\n","valid_loader = DataLoader(dataset=valid_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\n","# test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\n","\n","# print(len(train_loader))"]},{"cell_type":"code","execution_count":126,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:33:27.087278Z","iopub.status.busy":"2023-11-18T14:33:27.087008Z","iopub.status.idle":"2023-11-18T14:42:11.047384Z","shell.execute_reply":"2023-11-18T14:42:11.046307Z","shell.execute_reply.started":"2023-11-18T14:33:27.087252Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training accuracy is 0.32831427454948425\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  10%|█         | 1/10 [00:52<07:51, 52.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 0 complete! Validation Accuracy : 0.3750000298023224, Validation Loss : 1.589097023010254\n","Training accuracy is 0.34285715222358704\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  20%|██        | 2/10 [01:44<06:59, 52.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 complete! Validation Accuracy : 0.3800000250339508, Validation Loss : 1.56262238407135\n","Training accuracy is 0.4179143011569977\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  30%|███       | 3/10 [02:37<06:06, 52.36s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 complete! Validation Accuracy : 0.5550000071525574, Validation Loss : 1.2505229506492614\n","Training accuracy is 0.6155428290367126\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  40%|████      | 4/10 [03:29<05:14, 52.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 complete! Validation Accuracy : 0.7560000419616699, Validation Loss : 0.719032690346241\n","Training accuracy is 0.7585142850875854\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  50%|█████     | 5/10 [04:21<04:21, 52.37s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 complete! Validation Accuracy : 0.8470000624656677, Validation Loss : 0.4285176568329334\n","Training accuracy is 0.8299428224563599\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  60%|██████    | 6/10 [05:14<03:29, 52.37s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 complete! Validation Accuracy : 0.8820000290870667, Validation Loss : 0.3598316272050142\n","Training accuracy is 0.8665428757667542\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  70%|███████   | 7/10 [06:06<02:37, 52.40s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 complete! Validation Accuracy : 0.9280000329017639, Validation Loss : 0.21642951417714357\n","Training accuracy is 0.8901999592781067\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  80%|████████  | 8/10 [06:59<01:44, 52.45s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 complete! Validation Accuracy : 0.9450000524520874, Validation Loss : 0.15347789965569972\n","Training accuracy is 0.9175713658332825\n"]},{"name":"stderr","output_type":"stream","text":["Epoch:  90%|█████████ | 9/10 [07:51<00:52, 52.44s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 complete! Validation Accuracy : 0.9700000286102295, Validation Loss : 0.09104434096626937\n","Training accuracy is 0.9299999475479126\n"]},{"name":"stderr","output_type":"stream","text":["Epoch: 100%|██████████| 10/10 [08:43<00:00, 52.39s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 complete! Validation Accuracy : 0.968000054359436, Validation Loss : 0.10743766119051724\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["train(model=model, \n","      criterion=criterion,\n","      optimizer=optimizer, \n","      train_loader=train_loader,\n","      val_loader=valid_loader,\n","      epochs = 10,\n","     device = device)"]},{"cell_type":"code","execution_count":127,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T14:42:11.050778Z","iopub.status.busy":"2023-11-18T14:42:11.050359Z","iopub.status.idle":"2023-11-18T14:42:13.215992Z","shell.execute_reply":"2023-11-18T14:42:13.214986Z","shell.execute_reply.started":"2023-11-18T14:42:11.050731Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy : 0.968\n","f1 score macro : 0.956714283024313\n","f1 scoore micro : 0.968\n","Hamming loss : 0.032\n","Classification Report: \n","               precision    recall  f1-score   support\n","\n","           0       0.99      0.97      0.98       370\n","           1       1.00      0.95      0.97       272\n","           2       0.91      1.00      0.95       134\n","           3       0.96      0.97      0.96       113\n","           4       0.91      1.00      0.95        78\n","           5       0.97      0.88      0.92        33\n","\n","    accuracy                           0.97      1000\n","   macro avg       0.95      0.96      0.96      1000\n","weighted avg       0.97      0.97      0.97      1000\n","\n","Confusion Matrix: \n"," [[358   1   2   2   6   1]\n"," [  2 259   8   2   1   0]\n"," [  0   0 134   0   0   0]\n"," [  0   0   3 110   0   0]\n"," [  0   0   0   0  78   0]\n"," [  1   0   1   1   1  29]]\n"]}],"source":["actual_label, predicted_label = predict(model, valid_loader, device=device)\n","actual_label = np.array([item.to('cpu') for item in actual_label])\n","predicted_label = np.array([item.to('cpu') for item in predicted_label])\n","\n","print(\"Accuracy :\",metrics.accuracy_score(actual_label, predicted_label))\n","print(\"f1 score macro :\",metrics.f1_score(actual_label, predicted_label, average = 'macro'))\n","print(\"f1 scoore micro :\",metrics.f1_score(actual_label, predicted_label, average = 'micro'))\n","print(\"Hamming loss :\",metrics.hamming_loss(actual_label, predicted_label))\n","print(\"Classification Report: \\n\", classification_report(actual_label, predicted_label))\n","print(\"Confusion Matrix: \\n\", confusion_matrix(actual_label, predicted_label))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n","\n","# def plot_confusion_matrix(y_pred, y_true, labels):\n","#     cm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n","#     _, ax = plt.subplots(figsize=(6, 6))\n","#     disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","#     disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n","#     plt.title(\"Normalized confusion matrix\")\n","#     plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":605165,"sourceId":1085454,"sourceType":"datasetVersion"},{"datasetId":4009358,"sourceId":6996312,"sourceType":"datasetVersion"}],"dockerImageVersionId":30043,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
